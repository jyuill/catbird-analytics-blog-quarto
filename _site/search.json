[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Image & Code Specified",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "posts/r-time-series-vs-data-frame/index.html",
    "href": "posts/r-time-series-vs-data-frame/index.html",
    "title": "R Time Series Objects vs Data Frames: Advantages and Limitations",
    "section": "",
    "text": "As I learn more and more about R, questions often arise about which packages/methods/tools to use for a given situation. R is a vast - and growing - universe and I’m not interested in learning everything in that universe. I’m interested in learning the shortest paths between where I am now and my objective. As an adherent of the tidyverse, I lean strongly toward solutions in that realm. But, to paraphrase an old saying, ‘tidyverse is a playgound…not a jail’ and if a problem can be handled better by stepping outside the tidyverse, I’m all for that.\nOne of these areas is in dealing with time series: data sets comprised of repeated measurements over consistent time intervals (hourly, daily, monthly, etc). You can work with time series data using data frames, the fundamental building block of data analysis in R, but there are more specialized tools that offer more flexibility, specific capabilities and ease of use when analyzing time-based data. This can come into play in a wide variety of situations: weekly website visits, monthly sales, daily stock prices, annual GDP, electricity use by minute, that kind of thing.\nSo what are these time series advantages? How do we leverage them? What limitations of time series objects are good to be aware of? I’m not pretending this is a definitive guide, but I’ve been looking at this for a while and hear are my observations…\n(A word on forecasting: this is a MAJOR use case for time series but is not the main focus here and I’ll only touch on that briefly below.)\n\nTime Series Essentials\nts is the basic class for time series objects in R. You can do a lot with ts but its functionality have been extend by other packages, in particular zoo and more recently xts.\nxts is a leading, evolved R package for working with time series. It builds on zoo, an earlier pkg for handling time series in R. Datacamp has a very nice\nSo I’m just going to scratch the surface and hit some highlights with examples here.\n\nGet a Time Series Object\nAt its most basic, a time series object is a list or sometimes matrix of observations at regular time intervals.\nExamples in built-in R data sets include:\n\nannual Nile river flows\n\n\nclass(Nile)\n\n[1] \"ts\"\n\nstr(Nile)\n\n Time-Series [1:100] from 1871 to 1970: 1120 1160 963 1210 1160 1160 813 1230 1370 1140 ...\n\nNile\n\nTime Series:\nStart = 1871 \nEnd = 1970 \nFrequency = 1 \n  [1] 1120 1160  963 1210 1160 1160  813 1230 1370 1140  995  935 1110  994 1020\n [16]  960 1180  799  958 1140 1100 1210 1150 1250 1260 1220 1030 1100  774  840\n [31]  874  694  940  833  701  916  692 1020 1050  969  831  726  456  824  702\n [46] 1120 1100  832  764  821  768  845  864  862  698  845  744  796 1040  759\n [61]  781  865  845  944  984  897  822 1010  771  676  649  846  812  742  801\n [76] 1040  860  874  848  890  744  749  838 1050  918  986  797  923  975  815\n [91] 1020  906  901 1170  912  746  919  718  714  740\n\n\n\nmonthly Air Passengers - yes, I know everybody uses Air Passengers for their time series example. So damn handy. Different examples below, I promise. ;)\n\n\nclass(AirPassengers)\n\n[1] \"ts\"\n\nstr(AirPassengers)\n\n Time-Series [1:144] from 1949 to 1961: 112 118 132 129 121 135 148 148 136 119 ...\n\nAirPassengers\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949 112 118 132 129 121 135 148 148 136 119 104 118\n1950 115 126 141 135 125 149 170 170 158 133 114 140\n1951 145 150 178 163 172 178 199 199 184 162 146 166\n1952 171 180 193 181 183 218 230 242 209 191 172 194\n1953 196 196 236 235 229 243 264 272 237 211 180 201\n1954 204 188 235 227 234 264 302 293 259 229 203 229\n1955 242 233 267 269 270 315 364 347 312 274 237 278\n1956 284 277 317 313 318 374 413 405 355 306 271 306\n1957 315 301 356 348 355 422 465 467 404 347 305 336\n1958 340 318 362 348 363 435 491 505 404 359 310 337\n1959 360 342 406 396 420 472 548 559 463 407 362 405\n1960 417 391 419 461 472 535 622 606 508 461 390 432\n\n\nBoth these examples are time series of the ts class, and we can see right off that these are different data structures from data frames. A key thing to note about time series is that date/time is not in a column the way it would be in a data frame, but is in an index - similar to row.names in a data frame.\nIf we look at the index for the Nile river data, we can see the time values and we can check the start and end. This info corresponds to the structure info shown above, where start = 1871, end = 1970, and frequency = 1, meaning 1 observation per year, annual data.\n\nindex(Nile)\n\n  [1] 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885\n [16] 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900\n [31] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915\n [46] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930\n [61] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945\n [76] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960\n [91] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970\n\nstart(Nile)\n\n[1] 1871    1\n\nend(Nile)\n\n[1] 1970    1\n\n\nAs discussed above, ts is useful, but xts offers additional flexibility and features.\n\n\nConvert ts to xts\nConverting to an xts object can often make the data more intuitive to deal with.\n\nlibrary(xts)\nNile_xts <- as.xts(Nile)\nstr(Nile_xts)\n\nAn xts object on 1871-01-01 / 1970-01-01 containing: \n  Data:    double [100, 1]\n  Index:   Date [100] (TZ: \"UTC\")\n\nhead(Nile_xts)\n\n           [,1]\n1871-01-01 1120\n1872-01-01 1160\n1873-01-01  963\n1874-01-01 1210\n1875-01-01 1160\n1876-01-01 1160\n\n\n\nAir_xts <- as.xts(AirPassengers)\nstr(Air_xts)\n\nAn xts object on Jan 1949 / Dec 1960 containing: \n  Data:    double [144, 1]\n  Index:   yearmon [144] (TZ: \"UTC\")\n\nhead(Air_xts)\n\n         [,1]\nJan 1949  112\nFeb 1949  118\nMar 1949  132\nApr 1949  129\nMay 1949  121\nJun 1949  135\n\n\n\nWe can see here that xts has reshaped the data from a matrix with rows by year and columns by month to more ‘tidy’ data with mth-year as index and observations in one column.\n\n\n\nNative xts\nSome data comes as xts time series out of the box. For example, the quantmod package fetches stock market data as xts time series automatically:\n\nlibrary(quantmod)\n## use quantmod pkg to get some stock prices as time series\nprice <- getSymbols(Symbols='EA', from=\"2020-01-01\", to=Sys.Date(), auto.assign=FALSE)\nclass(price)\n\n[1] \"xts\" \"zoo\"\n\nhead(price)\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2020-01-02     108     108    107      107   1901000         106\n2020-01-03     106     108    105      107   1840300         106\n2020-01-06     107     109    107      109   2934200         107\n2020-01-07     109     109    108      108   1692400         107\n2020-01-08     108     110    108      109   2651600         108\n2020-01-09     110     110    108      109   1818600         108\n\n\nAs noted, a key characteristic of time series object is that dates are in an index rather than being in a date column, as they would be in typical data frame. Looking at the structure of the xts object, we can again see it is different from a data frame.\n\nstr(price)\n\nAn xts object on 2020-01-02 / 2023-04-06 containing: \n  Data:    double [822, 6]\n  Columns: EA.Open, EA.High, EA.Low, EA.Close, EA.Volume ... with 1 more column\n  Index:   Date [822] (TZ: \"UTC\")\n  xts Attributes:\n    $ src    : chr \"yahoo\"\n    $ updated: POSIXct[1:1], format: \"2023-04-08 16:50:35\"\n\n\n\n\nConvert xts to data frame\nIf you want to work with the time series as a data frame, it is fairly straightforward to convert an xts object:\n\nprice_df <- as.data.frame(price)\n## add Date field based on index (row names) of xts object\nprice_df$Date <- index(price)\n## set data frame row names to numbers instead of dates\nrownames(price_df) <- seq(1:nrow(price))\n## reorder columns to put Date first\nprice_df <- price_df %>% select(Date, 1:ncol(price_df)-1)\n## check out structure using glimpse, as is the fashion of the times\nglimpse(price_df)\n\nRows: 822\nColumns: 7\n$ Date        <date> 2020-01-02, 2020-01-03, 2020-01-06, 2020-01-07, 2020-01-0…\n$ EA.Open     <dbl> 108, 106, 107, 109, 108, 110, 109, 109, 110, 110, 110, 112…\n$ EA.High     <dbl> 108, 108, 109, 109, 110, 110, 109, 110, 110, 110, 111, 113…\n$ EA.Low      <dbl> 107, 105, 107, 108, 108, 108, 108, 109, 109, 109, 110, 112…\n$ EA.Close    <dbl> 107, 107, 109, 108, 109, 109, 109, 110, 110, 110, 111, 113…\n$ EA.Volume   <dbl> 1901000, 1840300, 2934200, 1692400, 2651600, 1818600, 1756…\n$ EA.Adjusted <dbl> 106, 106, 107, 107, 108, 108, 107, 108, 108, 108, 110, 111…\n\n\nData frame is basically a straight-up table, whereas the xts object has other structural features.\n\n\nConvert data frame to xts\n\n## convert data frame to xts object by specifying the date field to use for xts index.\nprice_xts <- xts(price_df, order.by=as.Date(price_df$Date))\nstr(price_xts)\n\nAn xts object on 2020-01-02 / 2023-04-06 containing: \n  Data:    character [822, 7]\n  Columns: Date, EA.Open, EA.High, EA.Low, EA.Close ... with 2 more columns\n  Index:   Date [822] (TZ: \"UTC\")\n\n\nNotice, however, that in the process of converting an xts object to data frame and back to xts, the xts Attributes information has been lost.\n\n\nSaving/Exporting time series data\nDue to the structure of an xts object, the best way to save/export for future use in R and preserve all its attributes is to save as RDS file, using saveRDS. (additional helpful RDS info here.)\nHowever, this won’t be helpful if you need to share the data with someone who is not using R. You can save as a CSV file using write.zoo (be sure to specificy sep=“,”) and this will maintain the table structure of the data but will drop the attributes. It will automatically move the indexes into an Index column so if someone opens it in Excel/Google Sheets, they will see the dates/times.\nSaving as RDS or CSV:\n\n## save as RDS to preserve attributes\nsaveRDS(price, file=\"price.rds\")\nprice_rds <- readRDS(file='price.rds')\nstr(price_rds)\n\nAn xts object on 2020-01-02 / 2023-04-06 containing: \n  Data:    double [822, 6]\n  Columns: EA.Open, EA.High, EA.Low, EA.Close, EA.Volume ... with 1 more column\n  Index:   Date [822] (TZ: \"UTC\")\n  xts Attributes:\n    $ src    : chr \"yahoo\"\n    $ updated: POSIXct[1:1], format: \"2023-04-08 16:50:35\"\n\n## save as CSV - ensure to include sep=\",\"\nwrite.zoo(price, file='price.csv', sep=\",\")\nprice_zoo <- read_csv('price.csv')\n\n\n\n\nTime Series Strengths\nThe structure of a time series leads a variety of advantages related to time-based analysis, compared to data frames. A few of the main ones, at least from my perspective:\n\nPeriod/Frequency Manipulation: can easily change from granular periods, such as daily, to aggregated periods.\nPeriod calculations: counting number of periods in the data (months, quarters, years).\nSelection/subsetting based on date ranges.\nVisualization: a number of visualization options are designed to work with time series.\nDecomposition: breaking out time series into trend, seasonal, random components for analysis.\nForecasting: time series objects are designed for applying various forecasting methods like Holt-Winters and ARIMA. This is well beyond the scope of this post, but we’ll show a quick ARIMA example.\n\nNo doubt everything you can do with time series can be done with data frames, but using a time series object can really expedite things.\n\n\nTime Series Manipulation/Calculation\n\nPeriod/Frequency Manipulation\nChange the period granularity to less granular:\n\neasily change daily data to weekly, monthly, quarterly, yearly\n\n\n## get periodicity (frequency) for data set\nperiodicity(price)\n\nDaily periodicity from 2020-01-02 to 2023-04-06 \n\n## aggregate by period\nhead(to.weekly(price)[,1:5])\n\n           price.Open price.High price.Low price.Close price.Volume\n2020-01-03        108        108       105         107      3741300\n2020-01-10        107        110       107         109     10852800\n2020-01-17        109        113       109         113     10221500\n2020-01-24        113        114       112         112      8457000\n2020-01-31        110        113       106         108     18435600\n2020-02-07        108        111       104         109     15973600\n\nhead(to.monthly(price)[,1:5])\n\n         price.Open price.High price.Low price.Close price.Volume\nJan 2020      107.9        114     105.1         108     51708200\nFeb 2020      107.9        111      98.6         101     55140000\nMar 2020      101.9        112      85.7         100    116497800\nApr 2020       98.4        119      96.7         114     72981400\nMay 2020      113.1        123     111.1         123     71400200\nJun 2020      123.3        134     113.3         132     64143400\n\nhead(to.yearly(price)[,1:5])\n\n           price.Open price.High price.Low price.Close price.Volume\n2020-12-31        108        147      85.7         144    747474600\n2021-12-31        143        150     120.1         132    641690700\n2022-12-30        132        143     109.2         122    547899700\n2023-04-06        124        131     108.5         125    167447300\n\n\nNotice that this isn’t a straight roll-up but actual summary: for the monthly data, the High is max of daily data for the month, the Low is minimum for the month, while volume is the sum for the month, all as you would expect.\nYou can also pull out the values at the END of a period-length, including setting number of periods to skip over each iteration:\n\nget index for last day of period length specified in ‘on’ for every k period.\napply index to dataset to extract the rows.\n\n\n## every 2 weeks (on='week's, k=2)\nend_wk <- endpoints(price, on=\"weeks\", k=2)\nhead(price[end_wk,])\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2020-01-03   105.6   107.8  105.1    107.2   1840300       105.7\n2020-01-17   112.4   113.0  111.6    112.9   3053300       111.4\n2020-01-31   110.8   110.8  105.5    107.9   6995800       106.5\n2020-02-14   108.9   109.9  108.8    109.7   1227500       108.2\n2020-02-28   100.3   101.9   98.6    101.4   6853700       100.0\n2020-03-13    98.7    99.6   92.8     97.1   5842000        95.7\n\n## every 6 months\nend_mth <- endpoints(price, on='months', k=6)\nhead(price[end_mth,])\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2020-06-30     133     133    131      132   2177400         130\n2020-12-31     142     144    142      144   1689900         142\n2021-06-30     144     145    143      144   1799900         142\n2021-12-31     134     135    132      132   1610900         131\n2022-06-30     122     123    121      122   2319000         121\n2022-12-30     122     122    121      122   1164400         122\n\n\nSee end of Period Calculations section for how to get an average during periods shown: averages for each 6 month period, for example.\n\n\nPeriod Counts\n\n## get the number of weeks, months, years in the dataset (including partial)\nprice_nw <- nweeks(price)\nprice_nm <- nmonths(price)\nprice_ny <- nyears(price)\n\nThe price data covers:\n\n822 days\n171 weeks\n40 months\n4 years (or portions thereof)\n\nFirst/last dates:\n\n## get earliest date\nst_date <- start(price)\n## get last date\nend_date <- end(price)\n\n\nStart: 2020-01-02\nEnd: 2023-04-06\n\n\n\nSelecting/Subsetting\nTime series objects make it easy to slice the data by date ranges. This is an area where time series really shine compared to trying to do the same thing with a data frame.\n\nxts is super-efficient at interpreting date ranges based on minimal info.\n‘/’ is a key symbol for separating dates - it is your friend.\ndate ranges are inclusive of references used.\n\nNote that in the following examples based on stock market data, dates are missing due to gaps in data - days when markets closed.\n\nquickly get entire YEAR\n\n\n## subset on a YEAR (showing head and tail to confirm data is 2021 only)\nhead(price[\"2021\"])\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2021-01-04     143     144    138      140   3587000         138\n2021-01-05     140     141    138      141   2117800         140\n2021-01-06     139     140    136      137   2398500         135\n2021-01-07     137     141    137      141   2936200         139\n2021-01-08     141     142    140      142   1902700         140\n2021-01-11     142     142    139      141   2589800         139\n\ntail(price[\"2021\"])\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2021-12-23     131     133    131      133   1594000         132\n2021-12-27     133     134    132      133   1377300         132\n2021-12-28     133     135    133      133   1230700         132\n2021-12-29     134     134    132      133    912300         132\n2021-12-30     134     136    134      134   1177000         133\n2021-12-31     134     135    132      132   1610900         131\n\n\n\nDURING selected month\n\n\n## get data DURING selected month\nprice[\"2020-02\"]\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2020-02-03     108     109  104.4      105   4155500         104\n2020-02-04     106     107  105.3      107   4190500         106\n2020-02-05     109     109  107.1      108   2895700         106\n2020-02-06     109     110  108.4      110   2500600         109\n2020-02-07     109     111  108.7      109   2231300         108\n2020-02-10     109     110  108.2      109   2170800         107\n2020-02-11     109     109  107.9      109   1195300         108\n2020-02-12     110     110  108.6      110   1567200         108\n2020-02-13     109     109  108.0      109   1627000         107\n2020-02-14     109     110  108.8      110   1227500         108\n2020-02-18     109     110  108.7      109   2171400         108\n2020-02-19     110     111  109.4      110   1540000         108\n2020-02-20     109     109  107.4      109   4034000         108\n2020-02-21     108     109  106.8      108   2546900         107\n2020-02-24     105     108  105.0      107   2817100         106\n2020-02-25     108     109  105.2      105   3651300         104\n2020-02-26     106     108  105.6      107   2858000         105\n2020-02-27     104     106  102.7      103   4906200         101\n2020-02-28     100     102   98.6      101   6853700         100\n\n\n\nFROM start of year to END OF SPECIFIC MONTH\n\n\n## get data FROM start of a year to END OF SPECIFIC MONTH\nprice_jf <- price[\"2021/2021-02\"]\nhead(price_jf, 4)\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2021-01-04     143     144    138      140   3587000         138\n2021-01-05     140     141    138      141   2117800         140\n2021-01-06     139     140    136      137   2398500         135\n2021-01-07     137     141    137      141   2936200         139\n\ntail(price_jf, 3)\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2021-02-24     138     140    137      138   3735500         136\n2021-02-25     137     139    134      135   3042600         134\n2021-02-26     136     138    134      134   3646600         132\n\n\n\neverything BEFORE specified date\n\n\n## get everything BEFORE specified date (based on what is avaliable)\nprice[\"/2020-01-06\"]\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2020-01-02     108     108    107      107   1901000         106\n2020-01-03     106     108    105      107   1840300         106\n2020-01-06     107     109    107      109   2934200         107\n\n\n\neverything BETWEEN two dates\n\n\n## get everything BETWEEN two dates\nprice[\"2021-06-01/2021-06-04\"]\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2021-06-01     142     144    142      144   2610300         142\n2021-06-02     144     144    141      141   1522100         140\n2021-06-03     141     143    141      142   1574900         141\n2021-06-04     143     146    143      145   1919500         144\n\n\n\neverything AFTER specified date\n\n\n## get everything AFTER specified date\nprice[\"2022-01-18/\"]\n\n           EA.Open EA.High  EA.Low EA.Close EA.Volume EA.Adjusted\n2022-01-18     138     143     133      134   8758900         133\n2022-01-19     136     138     135      137   3820300         136\n2022-01-20     138     142     138      139   3116900         138\n2022-01-21     138     141     138      139   3120000         138\n2022-01-24     137     139     132      135   4262100         134\n2022-01-25     134     134     130      131   2386400         130\n2022-01-26     131     132     129      130   2333800         129\n2022-01-27     131     134     131      131   1781500         130\n2022-01-28     131     132     130      132   2155000         131\n2022-01-31     131     136     129      133   4471000         132\n       ...                                                       \n2023-03-24     118     119     118      119   2527300         119\n2023-03-27     119     119     118      119   2276500         119\n2023-03-28     118     118     117      118   1551100         118\n2023-03-29     118     119     118      119   1522800         119\n2023-03-30     120     120     119      119   1979500         119\n2023-03-31     119     121     119      120   2346200         120\n2023-04-03     120     122     120      121   1946400         121\n2023-04-04     121     125     121      125   3303700         125\n2023-04-05     125     126     125      126   2564700         126\n2023-04-06     126     126     125      125   1991000         125\n\n\n\n\nPeriod Calculations\nTime series objects lend themselves well to time-based calculations.\nSimple arithmetic between two dates is not as straightforward as might be expected, but still easily doable:\n\n## subtraction of a given metric between two dates\nas.numeric(price$EA.Close[\"2022-01-21\"])-as.numeric(price$EA.Close[\"2022-01-18\"])\n\n[1] 5.1\n\n## subtraction of one metric from another on same date\nprice$EA.Close[\"2022-01-18\"]-price$EA.Open[\"2022-01-18\"]\n\n           EA.Close\n2022-01-18    -4.53\n\n\nLag.xts is versatile for lag calculations, calculating differences over time:\n\n## calculates across all columns with one command - default is 1 period but can be set with k\nhead(price-lag.xts(price))\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2020-01-02      NA      NA     NA       NA        NA          NA\n2020-01-03   -2.36   -0.60  -1.64    -0.14    -60700      -0.138\n2020-01-06    1.37    1.56   1.51     1.58   1093900       1.559\n2020-01-07    2.05   -0.06   1.10    -0.39  -1241800      -0.385\n2020-01-08   -0.82    0.75   0.05     1.10    959200       1.085\n2020-01-09    1.82    0.34   0.49    -0.13   -833000      -0.128\n\n## set k for longer lag - this example starting at a date beyond available data for the lag calculations, so no NAs\nhead(price[\"2020-01-13/\"]-lag.xts(price, k=7))\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2020-01-13    1.11    1.72   1.86     2.48    -43600       2.446\n2020-01-14    4.08    2.42   3.59     2.38   -116900       2.348\n2020-01-15    2.84    1.14   2.51     0.83  -1455100       0.819\n2020-01-16    1.00    2.04   2.22     2.87    415900       2.831\n2020-01-17    4.19    2.99   3.77     3.44    401700       3.393\n2020-01-21    2.55    2.63   3.50     3.05    346400       3.009\n\n## works for individual column\nprice$EA.Close[\"2022-01-18/\"]-lag.xts(price$EA.Close, k=2)\n\n           EA.Close\n2022-01-18     3.07\n2022-01-19     6.47\n2022-01-20     4.97\n2022-01-21     2.10\n2022-01-24    -3.68\n2022-01-25    -8.00\n2022-01-26    -5.22\n2022-01-27     0.05\n2022-01-28     1.94\n2022-01-31     1.60\n       ...         \n2023-03-24     5.87\n2023-03-27     2.60\n2023-03-28    -1.01\n2023-03-29     0.55\n2023-03-30     1.08\n2023-03-31     1.26\n2023-04-03     2.25\n2023-04-04     4.79\n2023-04-05     4.80\n2023-04-06    -0.08\n\n\nDiff for calculating differences, based on combination of lag and difference order:\n\nhead(diff(price, lag=1, differences=1))\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2020-01-02      NA      NA     NA       NA        NA          NA\n2020-01-03   -2.36   -0.60  -1.64    -0.14    -60700      -0.138\n2020-01-06    1.37    1.56   1.51     1.58   1093900       1.559\n2020-01-07    2.05   -0.06   1.10    -0.39  -1241800      -0.385\n2020-01-08   -0.82    0.75   0.05     1.10    959200       1.085\n2020-01-09    1.82    0.34   0.49    -0.13   -833000      -0.128\n\nhead(diff(price, lag=1, differences=2))\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2020-01-02      NA      NA     NA       NA        NA          NA\n2020-01-03      NA      NA     NA       NA        NA          NA\n2020-01-06    3.73    2.16   3.15     1.72   1154600        1.70\n2020-01-07    0.68   -1.62  -0.41    -1.97  -2335700       -1.94\n2020-01-08   -2.87    0.81  -1.05     1.49   2201000        1.47\n2020-01-09    2.64   -0.41   0.44    -1.23  -1792200       -1.21\n\n\n\nfirst example: diff with lag=1, differences=1 gives same result as lag.xts with k=1 (or default)\nsecond example: diff with differences=2 gives the ‘second order difference’: difference between the differences.\n\nEA.Open:\n\n3.73 = 1.37-(-2.36)\n0.68 = 2.05-1.37\n-2.87 = -0.82-2.05\n…\n\n\n\nUseful for some forecasting methods, among other applications.\nReturns for calculating % change period over period:\n\nfunctions in quantmod package designed for financial asset prices, but can be applied to other xts data.\nvarious periodicity: daily, weekly, monthly, quarterly, yearly or ALL at once (allReturn())\n\n\nhead(dailyReturn(price))\n\n           daily.returns\n2020-01-02      -0.00556\n2020-01-03      -0.00130\n2020-01-06       0.01474\n2020-01-07      -0.00359\n2020-01-08       0.01015\n2020-01-09      -0.00119\n\nhead(monthlyReturn(price))\n\n           monthly.returns\n2020-01-31       -0.000185\n2020-02-28       -0.060693\n2020-03-31       -0.011838\n2020-04-30        0.140661\n2020-05-29        0.075442\n2020-06-30        0.074626\n\n\n\napplied to Air Passenger xts to get % change, even though not financial returns:\n\n\nhead(monthlyReturn(Air_xts))\n\n         monthly.returns\nJan 1949          0.0000\nFeb 1949          0.0536\nMar 1949          0.1186\nApr 1949         -0.0227\nMay 1949         -0.0620\nJun 1949          0.1157\n\n\nAverage for period:\n\nUsing the indexes obtained in the ‘endpoints’ example at the end of the Period/Frequency Manipulation section above, calculate averages for the periods.\n\n\nperiod.apply(price, INDEX=end_mth, FUN=mean)\n\n           EA.Open EA.High EA.Low EA.Close EA.Volume EA.Adjusted\n2020-06-30     111     113    110      112   3454968         110\n2020-12-31     133     134    131      133   2465653         131\n2021-06-30     140     142    139      140   2508342         139\n2021-12-31     138     139    136      137   2583252         136\n2022-06-30     129     131    127      129   2530396         128\n2022-12-30     126     127    125      126   1843548         126\n2023-04-06     118     119    117      118   2537080         118\n\n\nRolling Average:\nYou can also calculate a rolling (moving) average quickly with ‘rollmean’ function from zoo:\n\n## get subset of data for demo\nprice_c <- price[,'EA.Close']\nprice_c <- price_c['/2020-02-28']\n## calc rolling mean and add to original data \n## - k=3 means 3-period lag\n## - align='right' put calculated number at last date in rolling period\nprice_c$EA_CLose_rm <- rollmean(price_c, k=3, align='right')\n\n## quick dygraph - more on this below\ndygraph(price_c, width='100%')\n\n\n\n\n\n\n\n\n\nVisualization\nTime series objects offer some different visualization opportunities than data frames. Below are a couple of options.\n\nPlot.ts\nYou can do a quick, simple plot with plot.ts(). Note that in this case the x-axis is the numerical index of the data point, and doesn’t show the date.\n\nplot.ts(price$EA.Close)\n\n\n\n\n\n\nDygraphs\nThe dygraphs package offers flexibility and interactivity for time series.\n\neasily show multiple metrics at once.\nscroll over to see details.\nselect chart area to zoom in.\n\n\nlibrary(dygraphs)\ndygraph(price[,1:4], width='100%')\n\n\n\n\n\n\n\nsubset for individual columns.\neasily add annotations for events.\n\n\n## use dyEvent to add annotations\ngraph <- dygraph(price$EA.Close, width='100%')\ngraph <- dyEvent(graph, \"2020-02-21\",\"Start of Covid 19\", labelLoc = 'top')\ngraph <- dyEvent(graph, \"2021-06-10\",\"New product announcements\", labelLoc = 'top')\n## print chart\ngraph\n\n\n\n\n\n\n\n\n\nDecomposition Plots\nDecomposition of a time series enables you to view it broken out into 3 key components (in addition to observed values):\n\noverall trend\nseasonality trending\nrandomness trend (noise)\n\nThis can make it easier to ‘separate the signal from the noise’ and get a clearer sense of what is going on.\nThere has to be data over a long enough period to assess any seasonal trend, so this requires:\n\nfrequency > 1, where 1=annual data; typically it would be at least 4 (quarterly), 12 (monthly), 52 (weekly), 365 (daily).\nperiod longer than 2 years: one year is not enough to establish a seasonal pattern over time.\n\nif you get ‘Error in decomposet(): time series has no or less than 2 periods’ it is usually due to violating one or both of the above conditions.\n\nneed to translate xts object to ts for this.\n\n\n## Air Passengers has enough data\nap_decomp <- decompose(AirPassengers)\nplot(ap_decomp)\n\n\n\napx_decomp <- decompose(ts(Air_xts, frequency=12))\nplot(apx_decomp)\n\n\n\n\n\nsame results with both approaches, although the original ts object maintains dates on x-axis, making it easier to interpret.\ninterpretation: steady upward trend; peaks at mid-year; randomness fairly large at first, settles down, then appears to be growing over time.\ncoincides with what we see in the observed data but makes the patterns more evident.\n\nIf we fetch some longer daily data for stock price, we can do the same:\n\n## fetch some longer price data\nprice_d <- getSymbols('EA', from='2016-01-01', to='2021-12-31', auto.assign = FALSE)\nprice_decomp <- decompose(ts(price_d$EA.Close, frequency=365), type=\"additive\")\nplot(price_decomp)\n\n\n\n\n\nwe provide 6 full years of data and most of that is used to calculated decomposition.\nx-axis is year number.\nTREND: trending up to about half-way through year 2, then down until about the same point in year 3, then back up, looking like a peak in mid year 4. Not willing to stretch out beyond that. ;)\nSEASONAL: pattern has been detected where tends to be a dip at beginning of year, rising up to a peak toward end of first quarter, dropping sharply, smaller peak mid-year, peak in q3 or early q4, drop with a smaller bump at end of year.\nRANDOM: as to be expected with stock price in general, lots of randomness involved!\n\nLooks like there may be money to be made riding the seasonal wave! Please: do not buy or sell stocks based on this information. ;)\n\n\nForecasting\nA primary use case for time series objects is forecasting. This is a whole other, involved topic way beyond the scope of this post.\nHere is a quick example to show how easy forecasting can be in R. Note that we need to bring in the forecast package for this. (There is also the amazing [tidyverts eco-system](https://tidyverts.org/) for working with time series that I have recently discovered - again, a whole other topic for another time.)\n\nGet an ARIMA Model\nSome basic terms, over-simplified for our purposes here:\n\nARIMA stands for Auto Regression Integrated Moving Average\nOne of the most widely-used time series forecasting methods, although certainly not the only.\n3 essential parameters for ARIMA are p,d,q: p=periods of lag, d=differencing, q=error of the model.\n\n\nlibrary(forecast)\n## get closing prices for forecasting\nprice_cl <- price[,4]\n## get a model for the time series - using auto.arima for simplicity\nfitA <- auto.arima(price_cl, seasonal=FALSE) ## can add trace=TRUE to see comparison of different models \n## show model\nfitA\n\nSeries: price_cl \nARIMA(0,1,0) \n\nsigma^2 = 5.11:  log likelihood = -1834\nAIC=3671   AICc=3671   BIC=3675\n\n\nThe model we get back is ARIMA(0,1,1) which means p=0, d=1, q=1. We can generate a model by setting these parameters manually, but auto.arima automatically checks a variety of models and selects the best. When comparing models, lowest AIC and BIC are preferred.\nWe can check the accuracy of the model. Most useful item here for interpretation and comparison is MAPE (mean average percent error). In this case,\n\n## check accuracy - based on historical data\naccuracy(fitA)\n\n                 ME RMSE  MAE     MPE MAPE  MASE    ACF1\nTraining set 0.0218 2.26 1.67 0.00169 1.33 0.999 -0.0405\n\nfitAa <- accuracy(fitA)\n100-fitAa[,5]\n\n[1] 98.7\n\n\nSo in this case a MAPE of 1.325 can be seen as accuracy of 98.675%.\nWe can also plot the residuals of the model for visual inspection.\n\n## check residuals\ntsdisplay(residuals(fitA), main='Residuals of Simple ARIMA Forecasting Model for Stock Price')\n\n\n\n\nAs usual with residuals, we are looking for mean around 0, roughly evenly distributed. For ARIMA we also get ACF and PACF, where we are looking for bars to be short and at least within blue dotted lines. So looks like we are good to go here.\n\n\nCreate A Forecast\nWe just need a little more code to create and plot forecast. We can set the forecast period for whatever we want, based on the periodicity of the data, in this case days and we are looking out 30 days.\n\ndays=30\nfcastA <- forecast(fitA, h=days)\nplot(fcastA)\n\n\n\n\nThat was easy! And we can use this approach to quickly iterate over various models, if we are not convinced that auto.arima is the best. Of course you can use data frames to create forecasts of various sorts but the xts object makes it super-easy to apply common time series methods.\nThis also reveals a shortcoming of times-series forecasting:\n\ndependence of pattern recognition and pattern repetition, which can lead to conservative forecast, especially with noisy data.\nas a result, the forecast is: ‘steady as she goes, with possibility of moving either quite a bit higher or quite a bit lower’.\n\nSo not that useful. To be fair, if stock market prices are not actually predictable, so it is a perfectly reasonable outcome that grounds us in reality.\n\n\n\nConclusion\nTimes series objects are obviously a powerful way to work with time-based data and a go-to when your data is based on time. Particular strengths inculde:\n\nEase of manipulation such as aggregation by date periods, selecting date ranges, period calculations.\nSome great visualization options for exploring the data.\nForecasting which is really the bread and butter of time series objects.\n\nThere are some cases where you may prefer to stick with data frames:\n\nMulti-dimensional data: time series work best when each row represents a distinct time. If you are dealing with multi-dimensional data where dates are broken down by customer, or region, etc., especially in tidy format, you may want to stick with data frame.\nVisualization preferences: if you are more comfortable with using ggplot2 (or other visualization tools geared toward data frames) a data frame may be preferable. Or if the document you are producing has ggplot2 charts, you may want to maintain standard presentation.\nForecasting needs: if you are doing time series forecasting you will want to use a time series object. If you’re not doing forecasting, there is less of a need. Limitation is that time series forecasting is based only on historical trends in the data and doesn’t include things like correlation with other factors.\n\nUltimately, the right tool for the job depends on a variety of situational factors, and having a collection of tools at your disposal helps you avoid the ‘when you have is a hammer…’ pitfall. If your data is based on time, time series should be in consideration.\nSo that’s quite a lot for one blog post - hopefully helps you make the most of your ‘time’!\n\n\nResources\nAdditional resources that may be helpful with time-series and xts in particular:\n\nxts Cheat Sheet.\nsupplementary info. to cheat sheet.\nxts package vignette.\ntime series section in R Cookbook 2nd Edition.\ntsibble package info. - time series for tidyverse."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!"
  },
  {
    "objectID": "posts/welcome/index.html#image",
    "href": "posts/welcome/index.html#image",
    "title": "Welcome To My Blog",
    "section": "Image",
    "text": "Image\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Catbird Analytics",
    "section": "",
    "text": "Post With Image & Code Specified\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2023\n\n\nJohn Yuill\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\nthe welcome post to make you feel welcome. and at home\n\n\n\n\n\n\nApr 5, 2023\n\n\nJohn Yuill\n\n\n\n\n\n\n  \n\n\n\n\nR Time Series Objects vs Data Frames: Advantages and Limitations\n\n\n\n\n\n\n\nR\n\n\ntime-series\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2022\n\n\nJohn Yuill\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Who am I?\nI’m John Yuill. I have close to 20 years of working with data to improve decision-making, in agency, consulting, and in-house roles. Most recently managing a marketing analytics team at EA in Vancouver, BC.\n\n\nWhat is Catbird Analytics?\nBeing a catbird is all about operating from the proverbial ‘catbird seat’: a vantage point that is far enough above the fray to see the big picture, while being close enough to the action to understand the details, maybe even swoop down to ground level once in a while, then return back to a perch to survey the situation.\nAnd when you combine that with the power of data & analysis, you get Catbird Analytics."
  },
  {
    "objectID": "posts/post-with-code/index.html#code-that-executes",
    "href": "posts/post-with-code/index.html#code-that-executes",
    "title": "Post With Image & Code Specified",
    "section": "Code that Executes",
    "text": "Code that Executes\nThis is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/post-with-code/index.html#more-code",
    "href": "posts/post-with-code/index.html#more-code",
    "title": "Post With Image & Code Specified",
    "section": "More Code",
    "text": "More Code\n\nGet data\n\nmtc <- mtcars\nsummary(mtc)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n\n\n\nExplore Data\n\nmtc %>% ggplot(aes(x=hp, y=mpg))+geom_point()"
  }
]